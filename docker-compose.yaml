version: '3.8'

services:
  mongo:
    build:
      context: . 
      dockerfile: ./dockerfiles/mongo/Dockerfile
    image: mongo_velas_miguel
    container_name: mongo
    ports:
      - 27017:27017
  mongo-express:
    image: mongo-express
    restart: "unless-stopped"
    ports:
      - 8081:8081
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: root
      ME_CONFIG_MONGODB_ADMINPASSWORD: example
      ME_CONFIG_MONGODB_URL: mongodb://mongo:27017
      ME_CONFIG_BASICAUTH: "false"

  kafka:
    build:
      context: .
      dockerfile: ./dockerfiles/kafka/Dockerfile
    image: kafka_velas_miguel
    container_name: kafka
    environment:
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_ADVERTISED_LISTENERS:PLAINTEXT://kafka:9092
    ports:
      - '9092:9092'

  spark-master:
    image: bde2020/spark-master:3.3.0-hadoop3.3
    container_name: spark-master
    depends_on:
      - proxy
    ports:
      - "7077:7077"
      - "9001:9001" 
      - "8080:8080" 
    environment:
      - "INIT_DAEMON_STEP=setup_spark"
      - "constraint:node==spark-master"
    volumes:
      -  ./practica_creativa:/practica_creativa
  spark-worker-1:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8083:8081"
    environment:
      - "INIT_DAEMON_STEP=setup_spark"
      - "constraint:node==spark-worker"
    volumes:
      -  ./practica_creativa:/practica_creativa
  spark-worker-2:
    image: bde2020/spark-worker:3.3.0-hadoop3.3
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - "INIT_DAEMON_STEP=setup_spark"
      - "constraint:node==spark-master"
    volumes:
      -  ./practica_creativa:/practica_creativa
    
  spark-submit:
    image: bde2020/spark-submit:3.3.0-hadoop3.3
    container_name: spark-submit
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2
      - cassandra
    ports:
      - "4040:4040"
    environment:
      - "SPARK_MASTER=spark://spark-master:7077"
      - "constraint:node==spark-master"
    command: bash -c "sleep 30; /spark/bin/spark-submit  --class  es.upm.dit.ging.predictor.MakePrediction --packages com.datastax.spark:spark-cassandra-connector_2.12:3.3.0,org.mongodb.spark:mongo-spark-connector_2.12:10.1.1,org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 --deploy-mode cluster --master spark://spark-master:7077 /practica_creativa/flight_prediction/target/scala-2.12/flight_prediction_2.12-0.1.jar"
    volumes:
      -  ./practica_creativa:/practica_creativa
  pyflask:
    build:
      context: .
      dockerfile: ./dockerfiles/pyflask/Dockerfile
    image: pyflask_velas_miguel
    container_name: pyflask
    hostname: python
    ports:
      - 5001:5001
    restart: always
  cassandra:
    build:
      context: .
      dockerfile: ./dockerfiles/cassandra/Dockerfile
    container_name: cassandra
    hostname: cassandra
    ports:
      - 9042:9042







    

version: '3.8'

services:
  mongo:
    build:
      context: . 
      dockerfile: ./dockerfiles/mongo/Dockerfile
    image: mongo_velas_miguel
    container_name: mongo
    ports:
      - 27017:27017


  kafka:
    build:
      context: .
      dockerfile: ./dockerfiles/kafka/Dockerfile
    image: kafka_velas_miguel
    container_name: kafka
    environment:
      - KAFKA_CFG_NODE_ID=0
      - KAFKA_CFG_PROCESS_ROLES=controller,broker
      - KAFKA_CFG_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_CFG_LISTENER_SECURITY_PROTOCOL_MAP=CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      - KAFKA_CFG_CONTROLLER_QUORUM_VOTERS=0@kafka:9093
      - KAFKA_CFG_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_ADVERTISED_LISTENERS:PLAINTEXT://kafka:9092
    ports:
      - '9092:9092'

  spark-master:
    image: bde2020/spark-master:3.2.1-hadoop3.2
    container_name: spark-master
    depends_on:
      - proxy
    ports:
      - "7077:7077"
      - "9001:9001" 
      - "8080:8080" 
    environment:
      - "SPARK_MASTER=${SPARK_MASTER}"
      - "INIT_DAEMON_STEP=setup_spark"
      - "constraint:node==spark-master"
      - "SERVER=${SERVER}"
    volumes:
      -  ./practica_creativa:/practica_creativa
  spark-worker-1:
    image: bde2020/spark-worker:3.2.1-hadoop3.2
    container_name: spark-worker-1
    depends_on:
      - spark-master
    ports:
      - "8081:8081"
    environment:
      - "SPARK_MASTER=${SPARK_MASTER}"
      - "INIT_DAEMON_STEP=setup_spark"
      - "constraint:node==spark-worker"
      - "SERVER=${SERVER}"
    volumes:
      -  ./practica_creativa:/practica_creativa

  spark-worker-2:
    image: bde2020/spark-worker:3.2.1-hadoop3.2
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - "SPARK_MASTER=${SPARK_MASTER}"
      - "constraint:node==spark-master"
      - "SERVER=${SERVER}"
    volumes:
      -  ./practica_creativa:/practica_creativa


  spark-worker-2:
    image: bde2020/spark-worker:3.2.1-hadoop3.2
    container_name: spark-worker-2
    depends_on:
      - spark-master
    ports:
      - "8082:8081"
    environment:
      - "SPARK_MASTER=${SPARK_MASTER}"
      - "constraint:node==spark-master"
      - "SERVER=${SERVER}"
    volumes:
      -  ./practica_creativa:/practica_creativa
    
  spark-submit:
    image: bde2020/spark-submit:3.2.1-hadoop3.2
    container_name: spark-submit
    depends_on:
      - spark-master
      - spark-worker-1
      - spark-worker-2
    ports:
      - "4040:4040"
    environment:
      - "SPARK_MASTER=${SPARK_MASTER}"
      - "constraint:node==spark-master"
      - "SERVER=${SERVER}"
    command: bash -c "sleep 15; /spark/bin/spark-submit  --class  es.upm.dit.ging.predictor.MakePrediction --packages org.mongodb.spark:mongo-spark-connector_2.12:10.1.1,org.apache.spark:spark-sql-kafka-0-10_2.12:3.3.0 --deploy-mode cluster --master spark://spark-master:7077 target/scala-2.12/flignt_prediction_2.12-0.1.jar"
    volumes:
      -  ./practica_creativa:/practica_creativa
  pyflask:
    build:
      context: .
      dockerfile: ./dockerfiles/pyflask/Dockerfile
    image: pyflask_velas_miguel
    container_name: pyflask
    depends_on:
      - mongo
      - kafka
    ports:
      - 5001:5001
    restart: always # Always restart the container if it crashes

 
 


    
